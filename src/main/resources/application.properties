spring.application.name=audit-spring-ai-ollama
#spring.ai.ollama.base-url= http://localhost:11434
#spring.ai.ollama.chat.options.model= qwen2.5:7b


spring.ai.openai.api-key=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
spring.ai.openai.base-url=https://integrate.api.nvidia.com
spring.ai.openai.chat.options.model=mistralai/mistral-nemotron

# The NVIDIA LLM API requires this parameter to be set explicitly or error will be thrown.
spring.ai.openai.chat.options.max-tokens=2048
server.port=8081
camunda.modeler.auth.client_id= e7AiEkvZZ3ZqjleO
camunda.modeler.auth.client_secret= uhcwuXzg50kSoxBkXFa99Sy8RVBGyUlT
camunda.modeler.auth.audience= api.cloud.camunda.io
camunda.modeler.auth.grant_type= client_credentials
camunda.modeler.auth.token_url= https://login.cloud.camunda.io/oauth/token
camunda.modeler.api.base_url= https://modeler.cloud.camunda.io/api/v1